{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a89bad06",
   "metadata": {},
   "source": [
    "# üîå Logic Gates Detection with YOLOv8 ‚Äì Type & Rotation Classification\n",
    "\n",
    "**Author:** Shahzaib Ahmad  \n",
    "**Platform:** Kaggle (GPU-accelerated training)  \n",
    "**Dataset:** [Logic Gates Type/Rotation Detection Dataset](https://www.kaggle.com/datasets/)\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Problem Statement\n",
    "\n",
    "In digital circuit design and educational tools, **automatic recognition of logic gates** from circuit diagrams is a valuable capability. This project tackles a **multi-class object detection problem** where the goal is to:\n",
    "\n",
    "1. **Detect** logic gates (AND, OR, NOT, NAND, NOR, XOR, XNOR) in circuit images\n",
    "2. **Classify** each gate's **type** and **rotation orientation**\n",
    "\n",
    "This is particularly useful for:\n",
    "- üéì **Educational software** that can grade student circuit drawings\n",
    "- üîß **Circuit digitization** tools converting hand-drawn schematics to digital formats\n",
    "- ü§ñ **Automation** in electronics manufacturing quality control\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Approach & Model Selection\n",
    "\n",
    "### Why Kaggle?\n",
    "\n",
    "This notebook was built on **Kaggle Notebooks** because it makes ML experiments easy to run, reproduce, and share:\n",
    "\n",
    "| Benefit | Why it matters |\n",
    "|---------|----------------|\n",
    "| **Free GPU acceleration** | Faster YOLO training without local hardware setup |\n",
    "| **Reproducible environment** | Consistent Docker-backed runtime (fewer ‚Äúworks on my machine‚Äù issues) |\n",
    "| **Dataset integration** | One-click access to datasets under `/kaggle/input` |\n",
    "| **Versioned outputs** | Models, logs, and plots saved under `/kaggle/working` and downloadable |\n",
    "| **Shareable notebook link** | Recruiters can open and review your full workflow end-to-end |\n",
    "\n",
    "Kaggle‚Äôs file layout also influences the implementation:\n",
    "- Read-only inputs live in `/kaggle/input/...`\n",
    "- Writable artifacts (patched YAML, trained weights, ZIP outputs) go to `/kaggle/working/...`\n",
    "\n",
    "### Model Configuration Choices\n",
    "\n",
    "- **Model Size:** `yolov8n` (nano) ‚Äì Fastest variant, ideal for this relatively simple detection task\n",
    "- **Image Size:** 1024px ‚Äì Higher resolution preserves gate details and orientation cues\n",
    "- **Optimizer:** AdamW with cosine learning rate schedule for smooth convergence\n",
    "- **Augmentation Strategy:** Carefully disabled rotation/flip augmentations since **rotation IS a class feature** we're detecting\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0444d8c3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-14T07:57:46.899762Z",
     "iopub.status.busy": "2025-08-14T07:57:46.899497Z",
     "iopub.status.idle": "2025-08-14T07:57:57.633378Z",
     "shell.execute_reply": "2025-08-14T07:57:57.632649Z"
    },
    "papermill": {
     "duration": 10.757117,
     "end_time": "2025-08-14T07:57:57.653270",
     "exception": false,
     "start_time": "2025-08-14T07:57:46.896153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3ed1f5",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Environment Setup\n",
    "\n",
    "First, we set up the Kaggle environment and explore the available input files. Kaggle provides a pre-configured Python environment with essential data science libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63598b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T07:57:57.719197Z",
     "iopub.status.busy": "2025-08-14T07:57:57.718799Z",
     "iopub.status.idle": "2025-08-14T07:59:14.147017Z",
     "shell.execute_reply": "2025-08-14T07:59:14.146202Z"
    },
    "papermill": {
     "duration": 76.452897,
     "end_time": "2025-08-14T07:59:14.148511",
     "exception": false,
     "start_time": "2025-08-14T07:57:57.695614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ff9514",
   "metadata": {},
   "source": [
    "## üîß Step 2: Install Ultralytics YOLOv8\n",
    "\n",
    "We install the latest version of Ultralytics, which provides the YOLOv8 implementation. The `-U` flag ensures we get the most recent version with all bug fixes and improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2691a5f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T07:59:14.250425Z",
     "iopub.status.busy": "2025-08-14T07:59:14.250140Z",
     "iopub.status.idle": "2025-08-14T07:59:19.740996Z",
     "shell.execute_reply": "2025-08-14T07:59:19.740127Z"
    },
    "papermill": {
     "duration": 5.542936,
     "end_time": "2025-08-14T07:59:19.742358",
     "exception": false,
     "start_time": "2025-08-14T07:59:14.199422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, glob, zipfile\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "DATASET_ROOT = \"/kaggle/input/logic-gates-typerotation-detection-dataset\"\n",
    "\n",
    "# Find data.yaml anywhere under the dataset root\n",
    "candidates = glob.glob(os.path.join(DATASET_ROOT, \"**\", \"data.yaml\"), recursive=True)\n",
    "if not candidates:\n",
    "    raise FileNotFoundError(f\"No data.yaml found under {DATASET_ROOT}. Check your dataset structure.\")\n",
    "found_yaml = candidates[0]\n",
    "print(\"Found data.yaml:\", found_yaml)\n",
    "\n",
    "# Heuristic: choose the base directory that actually contains images/train and images/val\n",
    "def find_base_dir(yaml_path, dataset_root):\n",
    "    p = Path(yaml_path).parent\n",
    "    # check current and a couple of ancestors\n",
    "    for root in [p, p.parent, p.parent.parent]:\n",
    "        if (root / \"images\" / \"train\").exists() and (root / \"images\" / \"val\").exists():\n",
    "            return str(root)\n",
    "    # fallback: search under the whole dataset root\n",
    "    trains = glob.glob(os.path.join(dataset_root, \"**\", \"images\", \"train\"), recursive=True)\n",
    "    for t in trains:\n",
    "        root = Path(t).parent.parent  # .../<root>/images/train -> <root>\n",
    "        if (root / \"images\" / \"val\").exists():\n",
    "            return str(root)\n",
    "    # last resort: parent of yaml\n",
    "    return str(p)\n",
    "\n",
    "base_dir = find_base_dir(found_yaml, DATASET_ROOT)\n",
    "print(\"Using base path for YAML 'path:':\", base_dir)\n",
    "\n",
    "# Load, patch, save\n",
    "with open(found_yaml, \"r\") as f:\n",
    "    y = yaml.safe_load(f)\n",
    "\n",
    "y[\"path\"] = base_dir  # keep your existing 'train: images/train', 'val: images/val'\n",
    "patched_yaml = \"/kaggle/working/data_patched.yaml\"\n",
    "with open(patched_yaml, \"w\") as f:\n",
    "    yaml.safe_dump(y, f, sort_keys=False)\n",
    "\n",
    "print(\"Patched yaml saved to:\", patched_yaml)\n",
    "print(\"---- data_patched.yaml ----\")\n",
    "print(open(patched_yaml).read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a43760",
   "metadata": {},
   "source": [
    "## üìÇ Step 3: Dataset Configuration & YAML Patching\n",
    "\n",
    "YOLO models require a `data.yaml` file that specifies:\n",
    "- **Path** to the dataset root\n",
    "- **Train/Val/Test** folder locations\n",
    "- **Class names** and their indices\n",
    "\n",
    "Since Kaggle datasets have a read-only structure, we need to:\n",
    "1. **Locate** the original `data.yaml` in the input directory\n",
    "2. **Patch** the `path` field to point to the correct base directory\n",
    "3. **Save** a modified copy to our writable working directory\n",
    "\n",
    "This ensures the model can find images and labels correctly during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a9fdfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T07:59:19.850101Z",
     "iopub.status.busy": "2025-08-14T07:59:19.849789Z",
     "iopub.status.idle": "2025-08-14T07:59:19.856032Z",
     "shell.execute_reply": "2025-08-14T07:59:19.855208Z"
    },
    "papermill": {
     "duration": 0.06279,
     "end_time": "2025-08-14T07:59:19.857296",
     "exception": false,
     "start_time": "2025-08-14T07:59:19.794506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile /kaggle/working/train_kaggle.py\n",
    "from ultralytics import YOLO\n",
    "import os, torch, shutil, sys\n",
    "from pathlib import Path\n",
    "\n",
    "def main(data_yaml_path):\n",
    "    # ---- config ----\n",
    "    DATA_YAML = data_yaml_path\n",
    "    MODEL = \"yolov8n.pt\"\n",
    "    EPOCHS = 100\n",
    "    IMGSZ = 1024\n",
    "    LR0 = 0.003\n",
    "    PATIENCE = 20\n",
    "    PROJECT = Path(\"runs/train\")\n",
    "    RUN_NAME = \"logic_gates_yolov8n\"\n",
    "    SEED = 42\n",
    "\n",
    "    # ---- device setup ----\n",
    "    USE_MULTI_GPU = True  # set to False to force single GPU with AutoBatch\n",
    "    if torch.cuda.is_available():\n",
    "        n = torch.cuda.device_count()\n",
    "        if USE_MULTI_GPU and n >= 2:\n",
    "            device = \"0,1\"\n",
    "            batch = 16          # MUST be a multiple of GPU count (2). Adjust if OOM.\n",
    "            workers = 8\n",
    "            amp = True\n",
    "            print(f\"Using multi-GPU: {device}  | batch={batch}\")\n",
    "        else:\n",
    "            device = \"0\"\n",
    "            batch = -1          # AutoBatch OK on single GPU\n",
    "            workers = 4\n",
    "            amp = True\n",
    "            print(f\"Using single GPU: {device}  | batch=Auto (-1)\")\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        batch = 8\n",
    "        workers = 2\n",
    "        amp = False\n",
    "        os.environ[\"OMP_NUM_THREADS\"] = \"8\"\n",
    "        os.environ[\"MKL_NUM_THREADS\"] = \"8\"\n",
    "        try:\n",
    "            torch.set_num_threads(8)\n",
    "        except Exception:\n",
    "            pass\n",
    "        print(\"Using CPU\")\n",
    "\n",
    "    # ---- train ----\n",
    "    model = YOLO(MODEL)\n",
    "    model.train(\n",
    "        data=DATA_YAML,\n",
    "        epochs=EPOCHS,\n",
    "        imgsz=IMGSZ,\n",
    "        batch=batch,\n",
    "        lr0=LR0,\n",
    "        patience=PATIENCE,\n",
    "        project=str(PROJECT),\n",
    "        name=RUN_NAME,\n",
    "        pretrained=True,\n",
    "        seed=SEED,\n",
    "        device=device,\n",
    "        workers=workers,\n",
    "        amp=amp,\n",
    "        optimizer=\"AdamW\",\n",
    "        cos_lr=True,\n",
    "\n",
    "        # rotation-safe augs (rotation is part of your classes)\n",
    "        hsv_h=0.0, hsv_s=0.0, hsv_v=0.0,\n",
    "        degrees=0.0, shear=0.0,\n",
    "        perspective=0.002,\n",
    "        translate=0.04, scale=0.20,\n",
    "        flipud=0.0, fliplr=0.0,\n",
    "        mosaic=0.5, close_mosaic=30,\n",
    "        mixup=0.0, copy_paste=0.0,\n",
    "\n",
    "        plots=True\n",
    "    )\n",
    "\n",
    "    # ---- copy best weights to /kaggle/working for download ----\n",
    "    best_src = PROJECT / RUN_NAME / \"weights\" / \"best.pt\"\n",
    "    out_best = \"/kaggle/working/best_model.pt\"\n",
    "    if best_src.exists():\n",
    "        shutil.copy2(best_src, out_best)\n",
    "        print(f\"‚úÖ Saved {out_best}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è best.pt not found at\", best_src)\n",
    "\n",
    "    # Optional scripted export (best_model.pt is the main file you need)\n",
    "    try:\n",
    "        model.export(format=\"pt\")\n",
    "        print(\"‚úÖ Exported scripted .pt (optional)\")\n",
    "    except Exception as e:\n",
    "        print(\"Export skipped:\", e)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) < 2:\n",
    "        raise SystemExit(\"Usage: python train_kaggle.py /kaggle/working/data_patched.yaml\")\n",
    "    main(sys.argv[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ae03c9",
   "metadata": {},
   "source": [
    "## üèãÔ∏è Step 4: Training Script Definition\n",
    "\n",
    "Here we define the complete training pipeline as a standalone Python script. This approach has several advantages:\n",
    "\n",
    "### Key Training Decisions:\n",
    "\n",
    "| Parameter | Value | Rationale |\n",
    "|-----------|-------|-----------|\n",
    "| `epochs=100` | Extended training for convergence with early stopping |\n",
    "| `imgsz=1024` | High resolution to capture fine gate details |\n",
    "| `lr0=0.003` | Conservative learning rate for stable fine-tuning |\n",
    "| `patience=20` | Early stopping to prevent overfitting |\n",
    "\n",
    "### Critical Augmentation Choices:\n",
    "\n",
    "Since **rotation is a class feature** (we're detecting gates at different orientations), we **disable spatial augmentations** that would confuse the model:\n",
    "\n",
    "```python\n",
    "degrees=0.0      # No random rotation\n",
    "flipud=0.0       # No vertical flips  \n",
    "fliplr=0.0       # No horizontal flips\n",
    "shear=0.0        # No shearing\n",
    "```\n",
    "\n",
    "We keep **color augmentations disabled** (`hsv_h/s/v=0.0`) since logic gate detection relies on shape, not color.\n",
    "\n",
    "### Multi-GPU Optimization:\n",
    "\n",
    "The script automatically detects available GPUs and configures:\n",
    "- **Dual GPU (Kaggle P100s):** Batch size 16, distributed training\n",
    "- **Single GPU:** AutoBatch for optimal memory usage\n",
    "- **CPU fallback:** Reduced batch size with multi-threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4e7400",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T07:59:19.973211Z",
     "iopub.status.busy": "2025-08-14T07:59:19.972847Z",
     "iopub.status.idle": "2025-08-14T11:47:24.466527Z",
     "shell.execute_reply": "2025-08-14T11:47:24.465702Z"
    },
    "papermill": {
     "duration": 13684.559424,
     "end_time": "2025-08-14T11:47:24.468075",
     "exception": false,
     "start_time": "2025-08-14T07:59:19.908651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python -u /kaggle/working/train_kaggle.py \"/kaggle/working/data_patched.yaml\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049f3677",
   "metadata": {},
   "source": [
    "## üöÄ Step 5: Execute Training\n",
    "\n",
    "Now we run the training script! This will:\n",
    "1. Load the pre-trained YOLOv8n weights (transfer learning from COCO)\n",
    "2. Fine-tune on our logic gates dataset\n",
    "3. Save the best model weights based on validation mAP\n",
    "4. Generate training plots and metrics\n",
    "\n",
    "**Expected runtime on Kaggle GPU:** ~30-60 minutes depending on dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9940e631",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T11:47:30.225751Z",
     "iopub.status.busy": "2025-08-14T11:47:30.225470Z",
     "iopub.status.idle": "2025-08-14T11:47:31.300160Z",
     "shell.execute_reply": "2025-08-14T11:47:31.299313Z"
    },
    "papermill": {
     "duration": 3.93575,
     "end_time": "2025-08-14T11:47:31.301279",
     "exception": false,
     "start_time": "2025-08-14T11:47:27.365529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, zipfile\n",
    "\n",
    "zip_path = \"/kaggle/working/outputs.zip\"\n",
    "with zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as z:\n",
    "    for fp in [\"/kaggle/working/best_model.pt\", \"/kaggle/working/data_patched.yaml\"]:\n",
    "        if os.path.exists(fp):\n",
    "            z.write(fp, arcname=os.path.basename(fp))\n",
    "    # include training runs (plots, metrics)\n",
    "    for root, _, files in os.walk(\"/kaggle/working/runs\"):\n",
    "        for fn in files:\n",
    "            full = os.path.join(root, fn)\n",
    "            rel = os.path.relpath(full, \"/kaggle/working\")\n",
    "            z.write(full, arcname=rel)\n",
    "\n",
    "print(\"Created:\", zip_path, \"\\nDownload from the right-side Output panel.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0ffc31",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Results & Key Takeaways\n",
    "\n",
    "### What to Expect from Training:\n",
    "\n",
    "After training completes, check the `runs/train/logic_gates_yolov8n/` folder for:\n",
    "\n",
    "| File | Description |\n",
    "|------|-------------|\n",
    "| `results.png` | Training/validation loss curves |\n",
    "| `confusion_matrix.png` | Per-class classification accuracy |\n",
    "| `PR_curve.png` | Precision-Recall curve |\n",
    "| `F1_curve.png` | F1 score vs confidence threshold |\n",
    "\n",
    "### Model Performance Interpretation:\n",
    "\n",
    "- **mAP@50** > 0.9: Excellent detection, ready for production\n",
    "- **mAP@50** 0.7-0.9: Good performance, may need more data or tuning\n",
    "- **mAP@50** < 0.7: Consider data quality, augmentation strategy, or larger model\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Inference:** Load `best_model.pt` with `YOLO()` for predictions\n",
    "2. **Optimization:** Export to ONNX/TensorRT for faster inference\n",
    "3. **Deployment:** Integrate into your circuit analysis application\n",
    "\n",
    "---\n",
    "\n",
    "## üôè Acknowledgments\n",
    "\n",
    "- **Dataset:** Logic Gates Type/Rotation Detection Dataset on Kaggle\n",
    "- **Framework:** [Ultralytics YOLOv8](https://github.com/ultralytics/ultralytics)\n",
    "- **Platform:** Kaggle Notebooks with GPU acceleration\n",
    "\n",
    "---\n",
    "\n",
    "*This notebook was developed on Kaggle using their free GPU resources. For best results, run with GPU acceleration enabled.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed571d48",
   "metadata": {},
   "source": [
    "## üì§ Step 6: Package Outputs for Download\n",
    "\n",
    "Finally, we bundle all training artifacts into a single ZIP file for easy download:\n",
    "\n",
    "- **`best_model.pt`** ‚Äì The trained model weights (use this for inference!)\n",
    "- **`data_patched.yaml`** ‚Äì Dataset configuration for reproducibility\n",
    "- **`runs/`** ‚Äì Training logs, metrics, and visualization plots"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8050220,
     "sourceId": 12735648,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13791.947141,
   "end_time": "2025-08-14T11:47:34.757717",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-14T07:57:42.810576",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
