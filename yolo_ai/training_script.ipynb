{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "jciCyM7yUnmA",
        "APbm61QuU_pu",
        "ScIilVP0VJkD",
        "2FCNi-lqVVw-",
        "s9P82-bT9HKV",
        "l7mWPqlEBoOZ"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preparation"
      ],
      "metadata": {
        "id": "jciCyM7yUnmA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To start off, follow these steps:\n",
        "* From the top menu bar, select **Runtime**.\n",
        "* Click on **change runtime type**.\n",
        "* Select GPU (preferably T4) and click **save**.\n",
        "\n",
        "Now run the cell bellow to confirm if GPU is available:"
      ],
      "metadata": {
        "id": "0a-ZEL4CAXXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrMZK_rKARSE",
        "outputId": "e28f2241-f4de-49a8-bc42-0ae93d61ece9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Aug 11 12:30:10 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the cell bellow to install ultralytics:"
      ],
      "metadata": {
        "id": "mmnnHRqI4yqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install ultralytics==8.3.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNIAlagN4hM5",
        "outputId": "a6b9c00d-76b8-4305-9976-1da4fb5ea1e3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m119.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Uploading the Dataset"
      ],
      "metadata": {
        "id": "APbm61QuU_pu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the official dataset from the links bellow:\n",
        "\n",
        "Details:\n",
        "* File name: dataset_yolo.zip\n",
        "* File size: 150mb\n",
        "* Version: 1.0\n",
        "\n",
        "Links:\n",
        "* [Kaggle](https://www.kaggle.com/datasets/shahzaibahmad05/logic-gates-typerotation-detection-dataset)\n",
        "* [Google Drive](https://drive.google.com/uc?export=download&id=1H22YKo60RVP0wAn1gruZzJOcp0HdeSIo\n",
        ")\n"
      ],
      "metadata": {
        "id": "cLL0LEb5X6mp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Run the cell bellow.\n",
        "* A **choose files** button will appear.\n",
        "* Upload dataset_yolo.zip\n",
        "* This should print *OK* for all 4 files."
      ],
      "metadata": {
        "id": "Qko8Wue75eCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()  # choose dataset_yolo.zip\n",
        "!unzip -q -o dataset_yolo.zip -d dataset_yolo\n",
        "\n",
        "from pathlib import Path\n",
        "for p in [\"dataset_yolo/images/train\",\"dataset_yolo/images/val\",\"dataset_yolo/labels/train\",\"dataset_yolo/labels/val\"]:\n",
        "    print(p, \"OK\" if Path(p).exists() else \"MISSING\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "BybcTP8XAgFR",
        "outputId": "b3262184-fc73-433b-c499-d958b66df48f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7b1610f2-c6c2-45c9-917c-c81c131ebdb6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7b1610f2-c6c2-45c9-917c-c81c131ebdb6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating the Training Script"
      ],
      "metadata": {
        "id": "ScIilVP0VJkD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the cell bellow to create the training script on the server:"
      ],
      "metadata": {
        "id": "-ecjHrON624B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train_yolov10.py\n",
        "import shutil\n",
        "import zipfile\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "# --- Hardcoded config ---\n",
        "DATA_YAML = Path(\"dataset_yolo/data.yaml\")\n",
        "MODEL = \"yolov10s.pt\"       # best balance for Colab T4\n",
        "EPOCHS = 120\n",
        "IMGSZ = 640\n",
        "BATCH = -1                  # auto-batch\n",
        "LR0 = 0.01\n",
        "PATIENCE = 30\n",
        "PROJECT = Path(\"runs/train\")\n",
        "RUN_NAME = \"logic_gates_yolov10s\"\n",
        "SEED = 42\n",
        "SAVE_PERIOD = 5  # <-- save & zip every 5 epochs\n",
        "\n",
        "# --- light dependency bootstrap (Colab-friendly) ---\n",
        "from ultralytics import YOLO\n",
        "from ultralytics.utils import SETTINGS\n",
        "SETTINGS['wandb'] = False  # disable wandb\n",
        "\n",
        "def _int_epoch_from_name(p: Path) -> int | None:\n",
        "    m = re.search(r\"epoch(\\d+)\\.pt$\", p.name)\n",
        "    return int(m.group(1)) if m else None\n",
        "\n",
        "def _latest_epoch_pt(weights_dir: Path) -> tuple[int | None, Path | None]:\n",
        "    \"\"\"Return (latest_epoch_number, path_to_epochN.pt) if present.\"\"\"\n",
        "    epoch_files = list(weights_dir.glob(\"epoch*.pt\"))\n",
        "    if not epoch_files:\n",
        "        return None, None\n",
        "    latest = max(epoch_files, key=lambda f: _int_epoch_from_name(f) or -1)\n",
        "    return _int_epoch_from_name(latest), latest\n",
        "\n",
        "def _zip_checkpoint(weights_dir: Path, epoch_number: int, out_dir: Path):\n",
        "    \"\"\"\n",
        "    Create a zip named after the epoch containing:\n",
        "      - epoch{N}.pt (if exists),\n",
        "      - last.pt,\n",
        "      - best.pt (if exists),\n",
        "      - selected run metadata (results.csv, args/hyp files if present).\n",
        "    \"\"\"\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    zip_path = out_dir / f\"checkpoint_epoch_{epoch_number}.zip\"\n",
        "    with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "        # Core weights\n",
        "        ep = weights_dir / f\"epoch{epoch_number}.pt\"\n",
        "        if ep.exists():\n",
        "            zf.write(ep, arcname=f\"weights/epoch{epoch_number}.pt\")\n",
        "        last = weights_dir / \"last.pt\"\n",
        "        if last.exists():\n",
        "            zf.write(last, arcname=\"weights/last.pt\")\n",
        "        best = weights_dir / \"best.pt\"\n",
        "        if best.exists():\n",
        "            zf.write(best, arcname=\"weights/best.pt\")\n",
        "\n",
        "        # Helpful run artifacts if available\n",
        "        run_root = weights_dir.parent  # runs/train/<name>\n",
        "        for cand in [\"results.csv\", \"hyp.yaml\", \"args.yaml\", \"opt.yaml\", \"metrics.json\"]:\n",
        "            p = run_root / cand\n",
        "            if p.exists():\n",
        "                zf.write(p, arcname=f\"run/{p.name}\")\n",
        "\n",
        "    print(f\"📦 Saved: {zip_path}\")\n",
        "    return zip_path\n",
        "\n",
        "def main():\n",
        "    if not DATA_YAML.exists():\n",
        "        raise SystemExit(f\"data.yaml not found at {DATA_YAML}. Run prepare_dataset.py first.\")\n",
        "\n",
        "    print(f\"Loading model: {MODEL}\")\n",
        "    model = YOLO(MODEL)\n",
        "\n",
        "    # Where outputs land\n",
        "    run_dir = PROJECT / RUN_NAME\n",
        "    weights_dir = run_dir / \"weights\"\n",
        "    zips_dir = run_dir / \"checkpoints_zips\"\n",
        "\n",
        "    epochs_done = 0\n",
        "    # Train in SAVE_PERIOD chunks so we can zip after each window\n",
        "    while epochs_done < EPOCHS:\n",
        "        chunk = min(SAVE_PERIOD, EPOCHS - epochs_done)\n",
        "        print(f\"\\n=== Training chunk: epochs {epochs_done} -> {epochs_done + chunk} (size={chunk}) ===\")\n",
        "\n",
        "        # First chunk: fresh; subsequent chunks: resume\n",
        "        resume_flag = epochs_done > 0\n",
        "\n",
        "        results = model.train(\n",
        "            data=str(DATA_YAML),\n",
        "            epochs=chunk,\n",
        "            imgsz=IMGSZ,\n",
        "            batch=BATCH,\n",
        "            lr0=LR0,\n",
        "            patience=PATIENCE,\n",
        "            project=str(PROJECT),\n",
        "            name=RUN_NAME,\n",
        "            exist_ok=True,\n",
        "            pretrained=True,\n",
        "            seed=SEED,\n",
        "            deterministic=False,\n",
        "            single_cls=False,\n",
        "\n",
        "            # Efficiency / stability\n",
        "            rect=False,         # allow mosaic\n",
        "            cos_lr=True,\n",
        "            amp=True,\n",
        "            device=\"0\",\n",
        "            workers=2,          # safer on Colab\n",
        "            cache=\"ram\",\n",
        "\n",
        "            # SAFE augmentations (do not change orientation)\n",
        "            hsv_h=0.015, hsv_s=0.5, hsv_v=0.4,\n",
        "            translate=0.08, scale=0.40,\n",
        "            mosaic=0.50,        # moderate mosaic; reduce if VRAM tight\n",
        "            close_mosaic=10,\n",
        "\n",
        "            # CRITICAL: disable orientation-changing augs\n",
        "            degrees=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0,\n",
        "\n",
        "            optimizer=\"AdamW\",\n",
        "            plots=True,\n",
        "            save_period=SAVE_PERIOD,  # will still emit epochN.pt within chunk if N hits the boundary\n",
        "            resume=resume_flag,\n",
        "        )\n",
        "\n",
        "        # After this chunk, locate the latest epochN.pt and zip state under that epoch number\n",
        "        latest_n, latest_ep_path = _latest_epoch_pt(weights_dir)\n",
        "        if latest_n is not None:\n",
        "            _zip_checkpoint(weights_dir, latest_n, zips_dir)\n",
        "        else:\n",
        "            print(\"[warn] No epoch*.pt found after this chunk; skipping zip.\")\n",
        "\n",
        "        epochs_done += chunk\n",
        "\n",
        "    print(\"✅ Training finished.\")\n",
        "\n",
        "    # Convenience copies at project root (optional)\n",
        "    best_src = weights_dir / \"best.pt\"\n",
        "    if best_src.exists():\n",
        "        shutil.copy2(best_src, \"best_model.pt\")\n",
        "        print(\"Saved: best_model.pt\")\n",
        "    else:\n",
        "        print(f\"[warn] best.pt not found at {best_src}\")\n",
        "\n",
        "    # Optional quick val\n",
        "    _ = model.val(data=str(DATA_YAML), imgsz=IMGSZ)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWUVJy5W6-pt",
        "outputId": "d961d0d4-0a7a-4aed-9c60-1d9e32459724"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing train_yolov10.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Important Step: Training"
      ],
      "metadata": {
        "id": "2FCNi-lqVVw-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "✔️ Quick Notes:\n",
        "* The training script would download a zip file every 5 epochs. Please keep it saved.\n",
        "* If the training is interrupted, resume it from the last save point. For guidance on this, check out **Resuming Section**.\n",
        "* This prevents progress loss due to interruptions.\n",
        "* Training may take upto 5–7 hours. Please be patient.\n",
        "\n",
        "Run the cell bellow to start training:"
      ],
      "metadata": {
        "id": "Jt8Hem_v5v9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_yolov10.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lK4Qxr16Go1X",
        "outputId": "4bdd33f1-a571-425e-fd51-8481e49ae835"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/train_yolov10.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Restore: Resuming when Interrupted"
      ],
      "metadata": {
        "id": "s9P82-bT9HKV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Follow these steps if the training was interrupted:\n",
        "* Make sure to run the cells in **Preparation** and **Uploading the Dataset** sections.\n",
        "* Then follow these steps bellow:"
      ],
      "metadata": {
        "id": "cEOKA2XV-qmy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Run** the cell bellow.\n",
        "* An **upload button** should appear.\n",
        "* Upload the zip file **last saved** by the training script. It would have been saved in your downloads folder as checkpoint_epoch_XX.zip"
      ],
      "metadata": {
        "id": "xYmfLSLv-3DV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "up = files.upload()  # pick your checkpoint_epoch_XX.zip\n",
        "zip_name = next(iter(up.keys()))\n",
        "print(\"Uploaded:\", zip_name)"
      ],
      "metadata": {
        "id": "f7_ske5S85AA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the cell bellow to **unpack the files** into the run directory:"
      ],
      "metadata": {
        "id": "xo5SxnpfAJpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import zipfile\n",
        "\n",
        "PROJECT = Path(\"/content/runs/train\")\n",
        "RUN_NAME = \"logic_gates_yolov10s\"\n",
        "run_dir = PROJECT / RUN_NAME\n",
        "run_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_name, \"r\") as zf:\n",
        "    zf.extractall(run_dir)\n",
        "\n",
        "# sanity check\n",
        "print(\"Extracted to:\", run_dir)\n",
        "!ls -lah \"/content/runs/train/logic_gates_yolov10s/weights\""
      ],
      "metadata": {
        "id": "YK2V-J4V88We"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resume training by running the following cell:"
      ],
      "metadata": {
        "id": "fRI8xzGyAUC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "last_ckpt = run_dir / \"weights\" / \"last.pt\"\n",
        "assert last_ckpt.exists(), f\"Missing: {last_ckpt}\"\n",
        "\n",
        "model = YOLO(str(last_ckpt))\n",
        "# resume=True restores optimizer, epoch count, etc.\n",
        "model.train(\n",
        "    resume=True,\n",
        "    project=str(PROJECT),\n",
        "    name=RUN_NAME,\n",
        ")"
      ],
      "metadata": {
        "id": "dmMUjvSh9AhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finishing"
      ],
      "metadata": {
        "id": "l7mWPqlEBoOZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the training is completed, run the cell bellow to download the trained model."
      ],
      "metadata": {
        "id": "zvn45njjB5kV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/runs/train/logic_gates_yolov10s/weights/best_model.pt')"
      ],
      "metadata": {
        "id": "ehmM0s11CbJI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}